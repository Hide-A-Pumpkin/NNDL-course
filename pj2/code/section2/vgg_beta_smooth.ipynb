{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG_beta_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm as tqdm\n",
    "from IPython import display\n",
    "\n",
    "from model.vgg import VGG_A\n",
    "from model.vgg_batchnorm import VGG_A_BatchNorm\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# train and evaluation function\n",
    "\n",
    "# Constants (parameters) initialization\n",
    "# device_id = [0,1,2,3]\n",
    "num_workers = 4\n",
    "batch_size = 64\n",
    "\n",
    "# add our package dir to path \n",
    "module_path = os.path.dirname(os.getcwd())\n",
    "home_path = module_path\n",
    "figures_path = os.path.join(home_path, 'reports', 'figures')\n",
    "models_path = os.path.join(home_path, 'reports', 'models')\n",
    "\n",
    "# Make sure you are using the right device.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "\n",
    "transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "# # load dataset from cifar10\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "validset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "val_loader = torch.utils.data.DataLoader(validset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "# This function is used to calculate the accuracy of model classification\n",
    "def get_accuracy(pred,y):\n",
    "    return pred.eq(y.view_as(pred)).sum().item()\n",
    "    \n",
    "# train function\n",
    "def train(model, optimizer, criterion, train_loader, val_loader, scheduler=None, epochs_n=100, best_model_path=None):\n",
    "    model.to(device)\n",
    "    learning_curve = [0] * epochs_n\n",
    "    train_accuracy_curve = [0] * epochs_n\n",
    "    val_accuracy_curve = [0] * epochs_n\n",
    "    max_val_accuracy = 0\n",
    "    max_val_accuracy_epoch = 0\n",
    "\n",
    "    batches_n = len(train_loader)\n",
    "    losses_list = []\n",
    "    grads = []\n",
    "    for epoch in tqdm(range(epochs_n), unit='epoch'):\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        model.train()\n",
    "\n",
    "        loss_list = []  # use this to record the loss value of each step\n",
    "        grad = []  # use this to record the loss gradient of each step\n",
    "        learning_curve[epoch] = 0  # maintain this to plot the training curve\n",
    "\n",
    "        for data in train_loader:\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            prediction = model(x)\n",
    "            loss = criterion(prediction, y)\n",
    "            # You may need to record some variable values here\n",
    "            # if you want to get loss gradient, use\n",
    "            # grad = model.classifier[4].weight.grad.clone()\n",
    "            loss_list.append(loss.item())\n",
    "            loss.backward()\n",
    "            \n",
    "            temp = model.classifier[4].weight.grad.clone()\n",
    "            # print(temp)\n",
    "            grad.append(temp)\n",
    "            \n",
    "            pred = prediction.argmax(dim = 1)\n",
    "\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "        losses_list.append(loss_list)\n",
    "        grads.append(grad)\n",
    "        display.clear_output(wait=True)\n",
    "        #f, axes = plt.subplots(1, 2, figsize=(15, 3))\n",
    "\n",
    "        #learning_curve[epoch] /= batches_n\n",
    "        #axes[0].plot(learning_curve)\n",
    "\n",
    "        # Test your model and save figure here (not required)\n",
    "        # remember to use model.eval()\n",
    "        model.eval()\n",
    "        batches_n = len(val_loader.dataset)\n",
    "        for data in val_loader:\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(x)\n",
    "            loss = criterion(prediction, y)\n",
    "            pred = prediction.argmax(dim = 1)\n",
    "            val_accuracy_curve[epoch] += get_accuracy(pred,y)\n",
    "            \n",
    "        val_accuracy_curve[epoch]  = val_accuracy_curve[epoch] /batches_n\n",
    "        if max_val_accuracy < val_accuracy_curve[epoch]:\n",
    "            max_val_accuracy = val_accuracy_curve[epoch]\n",
    "            max_val_accuracy_epoch = epoch\n",
    "        \n",
    "        print(\"epoch:{}, valid accuracy:{}, max valid accuracy:{}, max valid accuracy epoch:{}\".format(epoch, val_accuracy_curve[epoch], max_val_accuracy,max_val_accuracy_epoch))\n",
    "    \n",
    "\n",
    "    return losses_list, grads, val_accuracy_curve\n",
    "\n",
    "# change file save path\n",
    "epo = 20\n",
    "loss_save_path = ''\n",
    "grad_save_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_dist(grad,lr):\n",
    "    r = []\n",
    "    l = len(grad)\n",
    "    for i in range(l-1):\n",
    "        g1 = grad[i].cpu().numpy()\n",
    "        g2 = grad[i+1].cpu().numpy()\n",
    "        g_norm = np.linalg.norm(g2-g1)/(lr)\n",
    "        r.append(g_norm)\n",
    "    return r\n",
    "\n",
    "def VGG_Grad_Pred(VGG_A_grads,lr):\n",
    "    r = []\n",
    "    l = len(VGG_A_grads)\n",
    "    for i in range(l):\n",
    "        temp = l2_dist(VGG_A_grads[i],lr)\n",
    "        r.append(temp)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [05:25<00:00, 16.25s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19, valid accuracy:0.7754, max valid accuracy:0.7761, max valid accuracy epoch:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('----First model----'+'\\n')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "lr_list = [1e-3, 2e-3, 1e-4, 5e-4]\n",
    "loss_list = []\n",
    "grad_list = []\n",
    "for lr in lr_list:\n",
    "    model = VGG_A()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    VGG_A_loss, VGG_A_grads, val_accuracy_curve = train(model, optimizer, criterion, train_loader, val_loader, epochs_n=epo)\n",
    "    loss_list.append(VGG_A_loss)\n",
    "    \n",
    "    grads_l2_dist = VGG_Grad_Pred(VGG_A_grads,lr)\n",
    "    grad_list.append(grads_l2_dist)\n",
    "\n",
    "min_curve = []\n",
    "max_curve = []\n",
    "\n",
    "for epoch in range(epo):\n",
    "    eplen = len(grad_list[0][epoch])\n",
    "    for ele in range(eplen):\n",
    "        max_loss = max(grad_list[0][epoch][ele],grad_list[1][epoch][ele],grad_list[2][epoch][ele],grad_list[3][epoch][ele])\n",
    "        max_curve.append(max_loss)\n",
    "        min_loss = min(grad_list[0][epoch][ele],grad_list[1][epoch][ele],grad_list[2][epoch][ele],grad_list[3][epoch][ele])\n",
    "        min_curve.append(min_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [05:43<00:00, 17.15s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19, valid accuracy:0.8203, max valid accuracy:0.8325, max valid accuracy epoch:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('----Next model----'+'\\n')\n",
    "\n",
    "lr_list = [1e-3, 2e-3, 1e-4, 5e-4]\n",
    "loss_list = []\n",
    "grad_list = []\n",
    "for lr in lr_list:\n",
    "    model = VGG_A_BatchNorm()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    VGG_A_loss, VGG_A_grads, val_accuracy_curve = train(model, optimizer, criterion, train_loader, val_loader, epochs_n=epo)\n",
    "    loss_list.append(VGG_A_loss)\n",
    "    \n",
    "    grads_l2_dist = VGG_Grad_Pred(VGG_A_grads,lr)\n",
    "    grad_list.append(grads_l2_dist)\n",
    "\n",
    "\n",
    "min_curve_BN = []\n",
    "max_curve_BN = []\n",
    "for epoch in range(epo):\n",
    "    eplen = len(grad_list[0][epoch])\n",
    "    for ele in range(eplen):\n",
    "        max_loss = max(grad_list[0][epoch][ele],grad_list[1][epoch][ele],grad_list[2][epoch][ele],grad_list[3][epoch][ele])\n",
    "        max_curve_BN.append(max_loss)\n",
    "        min_loss = min(grad_list[0][epoch][ele],grad_list[1][epoch][ele],grad_list[2][epoch][ele],grad_list[3][epoch][ele])\n",
    "        min_curve_BN.append(min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(ls,fname):\n",
    "    f = open(fname, \"w\",encoding='UTF-8')\n",
    "    i = 0\n",
    "    for ele in ls:\n",
    "        i = i+1\n",
    "        f.write(str(ele)+'\\t')\n",
    "        if i % 100 == 0:\n",
    "            f.write('\\n')\n",
    "    f.close()\n",
    "    \n",
    "write_file(min_curve_BN,'min_curve2_BN.txt')\n",
    "write_file(max_curve_BN,'max_curve2_BN.txt')\n",
    "write_file(min_curve,'min_curve2.txt')\n",
    "write_file(max_curve,'max_curve2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_landscape(min_curve_BN, max_curve_BN, min_curve, max_curve):\n",
    "    plt.clf()\n",
    "    x = list(range(len(min_curve)))\n",
    "    x = np.array(x) \n",
    "    x_bn=list(range(len(min_curve_BN)))\n",
    "    min_curve_BN = np.array(min_curve_BN)[:len(min_curve)] \n",
    "    max_curve_BN = np.array(max_curve_BN)[:len(min_curve)]\n",
    "    min_curve = np.array(min_curve) \n",
    "    max_curve = np.array(max_curve) \n",
    "    \n",
    "    # ax1 = plt.subplot(1, 2, 1, frameon = False)\n",
    "    plt.plot(x, min_curve, color = 'blue',alpha=0.7)\n",
    "    plt.plot(x, max_curve, color = 'blue',alpha=0.7)\n",
    "    p1 = plt.fill_between(x, min_curve, max_curve, facecolor=\"blue\", alpha=0.3)\n",
    "    plt.title('Standard VGG')\n",
    "    plt.ylabel('beta-smoothness')\n",
    "    plt.xlabel('Step')\n",
    "    \n",
    "    # ax2 = plt.subplot(1, 2, 2, frameon = False)\n",
    "    plt.plot(x, min_curve_BN, color = 'red',alpha=0.7)\n",
    "    plt.plot(x, max_curve_BN, color = 'red',alpha=0.7)\n",
    "    p2 = plt.fill_between(x, min_curve_BN, max_curve_BN, facecolor=\"red\", alpha=0.3)\n",
    "    \n",
    "    \n",
    "    l1 = plt.legend([p1, p2], [\"VGG_A\", \"VGG_A_BatchNorm\"], loc='upper right')\n",
    "    plt.gca().add_artist(l1)\n",
    "    \n",
    "    plt.title('beta-smoothness')\n",
    "    \n",
    "    # plt.ylim((0, 6))\n",
    "    plt.savefig(\"beta-smooth.jpg\")\n",
    "\n",
    "def ReadFile(address):\n",
    "    f = open(address, encoding='UTF-8')\n",
    "    line = f.readline()\n",
    "    ls = []\n",
    "    while line:\n",
    "        line_ = line.replace('\\n','')\n",
    "        line_ = line_.split('\\t')\n",
    "        line_ = line_[:-1]\n",
    "        line_ = list(map(float,line_))\n",
    "        ls = ls + line_\n",
    "        line = f.readline()\n",
    "    f.close()\n",
    "    return ls\n",
    "\n",
    "\n",
    "min_curve_BN = ReadFile('min_curve2_BN.txt') \n",
    "max_curve_BN = ReadFile('max_curve2_BN.txt')\n",
    "min_curve = ReadFile('min_curve2.txt')\n",
    "max_curve = ReadFile('max_curve2.txt')\n",
    "plot_loss_landscape(min_curve_BN, max_curve_BN, min_curve, max_curve)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.5.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

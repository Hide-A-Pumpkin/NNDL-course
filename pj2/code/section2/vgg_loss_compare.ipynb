{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2-vgg accuracy compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm as tqdm\n",
    "from IPython import display\n",
    "\n",
    "from model.vgg import VGG_A\n",
    "from model.vgg_batchnorm import VGG_A_BatchNorm\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# train and evaluation function\n",
    "\n",
    "# ## Constants (parameters) initialization\n",
    "device_id = [0,1,2,3]\n",
    "num_workers = 4\n",
    "batch_size = 64\n",
    "\n",
    "# add our package dir to path \n",
    "module_path = os.path.dirname(os.getcwd())\n",
    "home_path = module_path\n",
    "figures_path = os.path.join(home_path, 'reports', 'figures')\n",
    "models_path = os.path.join(home_path, 'reports', 'models')\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2\"\n",
    "# Make sure you are using the right device.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "\n",
    "transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "# # load dataset from cifar10\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "validset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "val_loader = torch.utils.data.DataLoader(validset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# Set a random seed to ensure reproducible results\n",
    "def set_random_seeds(seed_value=0, device='cpu'):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    if device != 'cpu': \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# This function is used to calculate the accuracy of model classification\n",
    "def get_accuracy(pred,y):\n",
    "    return pred.eq(y.view_as(pred)).sum().item()\n",
    "\n",
    "# train function\n",
    "def train(model, optimizer, criterion, train_loader, val_loader, scheduler=None, epochs_n=100):\n",
    "    model.to(device)\n",
    "    learning_curve = [0] * epochs_n\n",
    "    train_accuracy_curve = [0] * epochs_n\n",
    "    val_accuracy_curve = [0] * epochs_n\n",
    "    max_val_accuracy = 0\n",
    "    max_val_accuracy_epoch = 0\n",
    "\n",
    "    batches_n = len(train_loader)\n",
    "    loss_list = []\n",
    "    grads = []\n",
    "    for epoch in tqdm(range(epochs_n), unit='epoch'):\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        model.train()\n",
    "\n",
    "        loss_list = []  # use this to record the loss value of each step\n",
    "        grad = []  # use this to record the loss gradient of each step\n",
    "        learning_curve[epoch] = 0  # maintain this to plot the training curve\n",
    "\n",
    "        for data in train_loader:\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(x)\n",
    "            loss = criterion(prediction, y)\n",
    "            loss_list.append(loss.item())\n",
    "            temp = model.classifier[4].weight.grad.clone()\n",
    "            grad.append(temp)\n",
    "            pred = prediction.argmax(dim = 1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        loss_list.append(loss_list)\n",
    "        grads.append(grad)\n",
    "        display.clear_output(wait=True)\n",
    "        f, axes = plt.subplots(1, 2, figsize=(15, 3))\n",
    "\n",
    "        learning_curve[epoch] /= batches_n\n",
    "        axes[0].plot(learning_curve)\n",
    "\n",
    "        model.eval()\n",
    "        batches_n = len(val_loader.dataset)\n",
    "        for data in val_loader:\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(x)\n",
    "            loss = criterion(prediction, y)\n",
    "            pred = prediction.argmax(dim = 1)\n",
    "            val_accuracy_curve[epoch] += get_accuracy(pred,y)\n",
    "            \n",
    "        val_accuracy_curve[epoch]  = val_accuracy_curve[epoch] /batches_n\n",
    "        if max_val_accuracy < val_accuracy_curve[epoch]:\n",
    "            max_val_accuracy = val_accuracy_curve[epoch]\n",
    "            max_val_accuracy_epoch = epoch\n",
    "        \n",
    "        print(\"epoch:{}, valid accuracy:{}, max valid accuracy:{}, max valid accuracy epoch:{}\".format(epoch, val_accuracy_curve[epoch], max_val_accuracy,max_val_accuracy_epoch))\n",
    "    \n",
    "\n",
    "    return loss_list, grads, val_accuracy_curve\n",
    "\n",
    "# change file save path\n",
    "loss_save_path = ''\n",
    "grad_save_path = ''\n",
    "\n",
    "# set random seed here \n",
    "set_random_seeds(seed_value=1234, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grad_cal(grad):\n",
    "    r = []\n",
    "    l = len(grad)\n",
    "    for i in range(l-1):\n",
    "        print(grad[i])\n",
    "        g1 = grad[i].cpu().numpy()\n",
    "        g2 = grad[i+1].cpu().numpy()\n",
    "        g_norm = np.linalg.norm(g2-g1)\n",
    "        r.append(g_norm)\n",
    "    return r\n",
    "    \n",
    "def VGG_Grad_Pred(VGG_A_grads):\n",
    "    r = []\n",
    "    l = len(VGG_A_grads)\n",
    "    for i in range(l):\n",
    "        temp = grad_cal(VGG_A_grads[i])\n",
    "        r.append(temp)\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:00<00:00, 12.12s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4, valid accuracy:0.6584, max valid accuracy:0.6584, max valid accuracy epoch:4\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb#ch0000005vscode-remote?line=12'>13</a>\u001b[0m     \u001b[39m# np.savetxt(os.path.join(loss_save_path, 'loss.txt'), VGG_A_loss, fmt='%s', delimiter=' ')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb#ch0000005vscode-remote?line=13'>14</a>\u001b[0m     \u001b[39m# np.savetxt(os.path.join(grad_save_path, 'grads.txt'), VGG_A_grads.cpu().numpy(), fmt='%s', delimiter=' ')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb#ch0000005vscode-remote?line=14'>15</a>\u001b[0m     loss_list\u001b[39m.\u001b[39mappend(VGG_A_loss)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb#ch0000005vscode-remote?line=15'>16</a>\u001b[0m     grads_l2_dist \u001b[39m=\u001b[39m VGG_Grad_Pred(VGG_A_grads)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb#ch0000005vscode-remote?line=16'>17</a>\u001b[0m     grad_list\u001b[39m.\u001b[39mappend(grads_l2_dist)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb#ch0000005vscode-remote?line=18'>19</a>\u001b[0m min_grad_curve \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32m/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb Cell 4'\u001b[0m in \u001b[0;36mVGG_Grad_Pred\u001b[0;34m(VGG_A_grads)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb#ch0000003vscode-remote?line=13'>14</a>\u001b[0m l \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(VGG_A_grads)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb#ch0000003vscode-remote?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(l):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb#ch0000003vscode-remote?line=15'>16</a>\u001b[0m     temp \u001b[39m=\u001b[39m grad_cal(VGG_A_grads[i])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb#ch0000003vscode-remote?line=16'>17</a>\u001b[0m     r\u001b[39m.\u001b[39mappend(temp)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb#ch0000003vscode-remote?line=17'>18</a>\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "\u001b[1;32m/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb Cell 4'\u001b[0m in \u001b[0;36mgrad_cal\u001b[0;34m(grad)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb#ch0000003vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(l\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb#ch0000003vscode-remote?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(grad[i])\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb#ch0000003vscode-remote?line=5'>6</a>\u001b[0m     g1 \u001b[39m=\u001b[39m grad[i]\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb#ch0000003vscode-remote?line=6'>7</a>\u001b[0m     g2 \u001b[39m=\u001b[39m grad[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/section2/vgg_loss_compare.ipynb#ch0000003vscode-remote?line=7'>8</a>\u001b[0m     g_norm \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(g2\u001b[39m-\u001b[39mg1)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "print('----First model----'+'\\n')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "epo = 5\n",
    "lr_list = [2e-3, 1e-3, 5e-4, 1e-4]\n",
    "loss_list = []\n",
    "grad_list = []\n",
    "for lr in lr_list:\n",
    "    model = VGG_A()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    VGG_A_loss, VGG_A_grads, val_accuracy_curve = train(model, optimizer, criterion, train_loader, val_loader, epochs_n=epo)\n",
    "    # np.savetxt(os.path.join(loss_save_path, 'loss.txt'), VGG_A_loss, fmt='%s', delimiter=' ')\n",
    "    # np.savetxt(os.path.join(grad_save_path, 'grads.txt'), VGG_A_grads.cpu().numpy(), fmt='%s', delimiter=' ')\n",
    "    loss_list.append(VGG_A_loss)\n",
    "    grads_l2_dist = VGG_Grad_Pred(VGG_A_grads)\n",
    "    grad_list.append(grads_l2_dist)\n",
    "\n",
    "min_grad_curve = []\n",
    "max_grad_curve = []\n",
    "max_curve=[]\n",
    "min_curve=[]\n",
    "\n",
    "for epoch in range(epo):\n",
    "    eplen = len(loss_list[0][epoch])\n",
    "    for ele in range(eplen):\n",
    "        max_loss = max(loss_list[0][epoch][ele],loss_list[1][epoch][ele],loss_list[2][epoch][ele],loss_list[3][epoch][ele])\n",
    "        max_curve.append(max_loss)\n",
    "        min_loss = min(loss_list[0][epoch][ele],loss_list[1][epoch][ele],loss_list[2][epoch][ele],loss_list[3][epoch][ele])\n",
    "        min_curve.append(min_loss)\n",
    "        max_grad = max(grad_list[0][epoch][ele],grad_list[1][epoch][ele],grad_list[2][epoch][ele],grad_list[3][epoch][ele])\n",
    "        max_grad_curve.append(max_grad)\n",
    "        min_grad = min(grad_list[0][epoch][ele],grad_list[1][epoch][ele],grad_list[2][epoch][ele],grad_list[3][epoch][ele])\n",
    "        min_grad_curve.append(min_grad)\n",
    "    \n",
    "def write_file(ls,fname):\n",
    "    f = open(fname, \"w\",encoding='UTF-8')\n",
    "    i = 0\n",
    "    for ele in ls:\n",
    "        i = i+1\n",
    "        f.write(str(ele)+'\\t')\n",
    "        if i % 100 == 0:\n",
    "            f.write('\\n')\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----Next model----'+'\\n')\n",
    "\n",
    "\n",
    "loss_list = []\n",
    "grad_list = []\n",
    "for lr in lr_list:\n",
    "    model = VGG_A_BatchNorm()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    VGG_A_loss, VGG_A_grads, val_accuracy_curve = train(model, optimizer, criterion, train_loader, val_loader, epochs_n=epo)\n",
    "    loss_list.append(VGG_A_loss)\n",
    "    grads_l2_dist = VGG_Grad_Pred(VGG_A_grads)\n",
    "    grad_list.append(grads_l2_dist)\n",
    "\n",
    "\n",
    "min_curve_BN = []\n",
    "max_curve_BN = []\n",
    "min_grad_curve_BN = []\n",
    "max_grad_curve_BN = []\n",
    "\n",
    "for epoch in range(epo):\n",
    "    eplen = len(loss_list[0][epoch])\n",
    "    for ele in range(eplen):\n",
    "        max_loss = max(loss_list[0][epoch][ele],loss_list[1][epoch][ele],loss_list[2][epoch][ele],loss_list[3][epoch][ele])\n",
    "        max_curve_BN.append(max_loss)\n",
    "        min_loss = min(loss_list[0][epoch][ele],loss_list[1][epoch][ele],loss_list[2][epoch][ele],loss_list[3][epoch][ele])\n",
    "        min_curve_BN.append(min_loss)\n",
    "        max_grad = max(grad_list[0][epoch][ele],grad_list[1][epoch][ele],grad_list[2][epoch][ele],grad_list[3][epoch][ele])\n",
    "        max_grad_curve_BN.append(max_grad)\n",
    "        min_grad = min(grad_list[0][epoch][ele],grad_list[1][epoch][ele],grad_list[2][epoch][ele],grad_list[3][epoch][ele])\n",
    "        min_grad_curve_BN.append(min_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(min_curve_BN,'min_grad_curve_BN.txt')\n",
    "write_file(max_curve_BN,'max_grad_curve_BN.txt')\n",
    "write_file(min_curve,'min_grad_curve.txt')\n",
    "write_file(max_curve,'max_grad_curve.txt')\n",
    "write_file(min_curve_BN,'min_loss_curve_BN.txt')\n",
    "write_file(max_curve_BN,'max_loss_curve_BN.txt')\n",
    "write_file(min_curve,'min_loss_curve.txt')\n",
    "write_file(max_curve,'max_loss_curve.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot function\n",
    "def plot_loss_landscape(min_curve_BN, max_curve_BN, min_curve, max_curve):\n",
    "    plt.clf()\n",
    "    x = list(range(len(min_curve)))\n",
    "    x = np.array(x) \n",
    "    min_curve_BN = np.array(min_curve_BN) \n",
    "    max_curve_BN = np.array(max_curve_BN) \n",
    "    min_curve = np.array(min_curve) \n",
    "    max_curve = np.array(max_curve) \n",
    "    \n",
    "    plt.subplot(1,1,1)\n",
    "    plt.ylim(0,8)\n",
    "    plt.plot(x, min_curve,'b')\n",
    "    plt.plot(x, max_curve, 'b')\n",
    "    p1 = plt.fill_between(x, min_curve, max_curve, facecolor=\"blue\", alpha=1)\n",
    "    \n",
    "    plt.plot(x, min_curve_BN, 'r')\n",
    "    plt.plot(x, max_curve_BN, 'r')\n",
    "    p2 = plt.fill_between(x, min_curve_BN, max_curve_BN, facecolor=\"red\", alpha=1)\n",
    "    \n",
    "    l1 = plt.legend([p1, p2], [\"VGG_A\", \"VGG_A_BatchNorm\"], loc='upper right')\n",
    "    plt.title('Loss_landscape vs Steps')\n",
    "    plt.ylabel('Loss_landscape')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.savefig(\"Loss_landscape_update.jpg\")\n",
    "    plt.gca().add_artist(l1)\n",
    "    \n",
    "def ReadFile(address):\n",
    "    f = open(address, encoding='UTF-8')\n",
    "    line = f.readline()\n",
    "    ls = []\n",
    "    while line:\n",
    "        line_ = line.replace('\\n','')\n",
    "        line_ = line_.split('\\t')\n",
    "        line_ = line_[:-1]\n",
    "        line_ = list(map(float,line_))\n",
    "        ls = ls + line_\n",
    "        line = f.readline()\n",
    "    f.close()\n",
    "    return ls\n",
    "\n",
    "PATH='/home/newdisk/zxy/pj2/codes_for_pj/section2/draw/Loss/'\n",
    "min_curve_BN = ReadFile('min_curve_BN.txt') \n",
    "max_curve_BN = ReadFile('max_curve_BN.txt')\n",
    "min_curve = ReadFile('min_curve.txt')\n",
    "max_curve = ReadFile('max_curve.txt')\n",
    "\n",
    "plot_loss_landscape(min_curve_BN, max_curve_BN, min_curve, max_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

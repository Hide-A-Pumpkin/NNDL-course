{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# newModel train & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm as tqdm\n",
    "import time\n",
    "\n",
    "# from models.my_model import MyNet, train, evaluate, evaluate_test\n",
    "from torchvision import datasets, transforms\n",
    "from data.loaders import get_cifar_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cuda\n",
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "PATH=\"data/cifar-10-python.tar.gz\"\n",
    "\n",
    "module_path = os.path.dirname(os.getcwd())\n",
    "home_path = module_path\n",
    "figures_path = os.path.join(home_path, 'reports', 'figures')\n",
    "models_path = os.path.join(home_path, 'reports', 'models')\n",
    "\n",
    "transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "# # load dataset from cifar10\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "validset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_dataloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# choose device as cuda\n",
    "# device_id = device_id\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# device = torch.device(\"cuda:{}\".format(3) if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(3))\n",
    "\n",
    "module_path = os.path.dirname(os.getcwd())\n",
    "home_path = module_path\n",
    "figures_path = os.path.join(home_path, 'reports', 'figures')\n",
    "models_path = os.path.join(home_path, 'reports', 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self,num_features,hidden_size,output_size):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_features, 64, 5, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 5, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(1600, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x:1 * 28 * 28\n",
    "        \n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = F.relu(x) # 20 * 28 * 28\n",
    "        print(x.shape)\n",
    "        x = F.max_pool2d(x, 2, 2) # 20 * 14 * 14\n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = F.relu(x) # 20 * 10* 10\n",
    "        print(x.shape)\n",
    "        x = F.max_pool2d(x, 2, 2) # 50 * 5 * 5\n",
    "        print(x.shape)\n",
    "        \n",
    "        x = x.view(-1, 1600) #reshape\n",
    "        print(x.shape)\n",
    "        x1 = F.relu(self.fc1(x))\n",
    "        # x1 = F.max_pool2d(x1, 2, 2) \n",
    "        x1 = self.dropout(x1)\n",
    "        x1 = self.fc2(x1)\n",
    "        \n",
    "        return F.log_softmax(x1, dim = 1) # log probability\n",
    "\n",
    "\n",
    "class myVGGNet(nn.Module):\n",
    "    def __init__(self,num_features, hidden_size, output_size):\n",
    "        super(testNet,self).__init__()\n",
    "        \n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(num_features,64,3,padding=1),\n",
    "            nn.Conv2d(64,64,3,padding=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(64,128,3,padding=1),\n",
    "            nn.Conv2d(128, 128, 3,padding=1),\n",
    "            nn.MaxPool2d(2, 2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(128,128, 3,padding=1),\n",
    "            nn.Conv2d(128, 128, 3,padding=1),\n",
    "            nn.Conv2d(128, 128, 1,padding=1),\n",
    "            nn.MaxPool2d(2, 2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3,padding=1),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.Conv2d(256, 256, 1, padding=1),\n",
    "            nn.MaxPool2d(2, 2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.Conv2d(512, 512, 1, padding=1),\n",
    "            nn.MaxPool2d(2, 2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        \n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Linear(512*4*4,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(1024,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(hidden_size,output_size)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        # x = self.avgpool(x)\n",
    "        x = x.view(-1,512*4*4)\n",
    "        \n",
    "        x = self.layer5(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train(model, device, train_dataloader, optimizer, epoch, loss_fn):\n",
    "    model.train()\n",
    "\n",
    "    for idx, (data, target) in enumerate(train_dataloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        preds = model(data) # batch_size * 10\n",
    "        loss = loss_fn(preds, target)\n",
    "        # loss = F.nll_loss(preds,target)\n",
    "        # 前向传播+反向传播+优化\n",
    "        # loss = F.CrossEntropyLoss(preds, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 1000 == 0:\n",
    "            print(\"iteration: {};    Loss: {}\".format(idx, loss.item()))\n",
    "\n",
    "def evaluate(model, device, valid_dataloader,loss_fn, flag):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    correct = 0.\n",
    "    total_len = len(valid_dataloader.dataset)\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, target) in enumerate(valid_dataloader):\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data) # batch_size * 1\n",
    "            total_loss += loss_fn(output, target).item()\n",
    "            # total_loss += F.nll_loss(output, target, reduction = \"sum\").item()\n",
    "            pred = output.argmax(dim = 1)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    total_loss = total_loss / total_len\n",
    "    acc = correct/total_len\n",
    "    if flag == 1:\n",
    "        print(\"Accuracy on test set:{}\".format(acc)) \n",
    "    else:\n",
    "        print(\"valid loss:{}, Accuracy:{}\".format(total_loss, acc)) \n",
    "    return total_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 28, 28])\n",
      "torch.Size([64, 64, 14, 14])\n",
      "torch.Size([64, 64, 10, 10])\n",
      "torch.Size([64, 64, 5, 5])\n",
      "torch.Size([64, 1600])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "non-empty 3D or 4D (batch mode) tensor expected for input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000005vscode-remote?line=17'>18</a>\u001b[0m total_loss \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000005vscode-remote?line=18'>19</a>\u001b[0m acc \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000005vscode-remote?line=20'>21</a>\u001b[0m train(model, device, train_dataloader, optimizer1, \u001b[39m0\u001b[39;49m, loss_fn)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000005vscode-remote?line=21'>22</a>\u001b[0m total_loss_0, acc_0 \u001b[39m=\u001b[39m evaluate(model, device, valid_dataloader,loss_fn, \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000005vscode-remote?line=22'>23</a>\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(),\u001b[39m\"\u001b[39m\u001b[39mCIFAR10_cnn.pth\u001b[39m\u001b[39m\"\u001b[39m)    \n",
      "\u001b[1;32m/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb Cell 5'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_dataloader, optimizer, epoch, loss_fn)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000004vscode-remote?line=114'>115</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, (data, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000004vscode-remote?line=115'>116</a>\u001b[0m     data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000004vscode-remote?line=116'>117</a>\u001b[0m     preds \u001b[39m=\u001b[39m model(data) \u001b[39m# batch_size * 10\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000004vscode-remote?line=117'>118</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(preds, target)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000004vscode-remote?line=118'>119</a>\u001b[0m     \u001b[39m# loss = F.nll_loss(preds,target)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000004vscode-remote?line=119'>120</a>\u001b[0m     \u001b[39m# 前向传播+反向传播+优化\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000004vscode-remote?line=120'>121</a>\u001b[0m     \u001b[39m# loss = F.CrossEntropyLoss(preds, target)\u001b[39;00m\n",
      "File \u001b[0;32m/home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb Cell 5'\u001b[0m in \u001b[0;36mMyNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000004vscode-remote?line=28'>29</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000004vscode-remote?line=29'>30</a>\u001b[0m x1 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000004vscode-remote?line=30'>31</a>\u001b[0m x1 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmax_pool2d(x1, \u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m) \u001b[39m# 50 * 5 * 5\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000004vscode-remote?line=31'>32</a>\u001b[0m x1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x1)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224644555f696e227d/home/newdisk/zxy/pj2/codes_for_pj/test.ipynb#ch0000004vscode-remote?line=32'>33</a>\u001b[0m x1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x1)\n",
      "File \u001b[0;32m/home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/torch/_jit_internal.py:422\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/torch/_jit_internal.py?line=419'>420</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/torch/_jit_internal.py?line=420'>421</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/torch/_jit_internal.py?line=421'>422</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/torch/nn/functional.py:797\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    <a href='file:///home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/torch/nn/functional.py?line=794'>795</a>\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/torch/nn/functional.py?line=795'>796</a>\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[0;32m--> <a href='file:///home/newdisk/zxy/zxy_virtualenv/lib/python3.8/site-packages/torch/nn/functional.py?line=796'>797</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: non-empty 3D or 4D (batch mode) tensor expected for input"
     ]
    }
   ],
   "source": [
    "# hyper parameter\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "weight_decay = 1e-5\n",
    "num_features = 3\n",
    "hidden_size = 1024\n",
    "output_size = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model = MyNet(num_features,hidden_size,output_size).to(device)\n",
    "#选择一个optimizer\n",
    "#SGD/ADAM\n",
    "optimizer1 = torch.optim.SGD(model.parameters(), lr = lr, momentum=momentum,weight_decay=weight_decay)\n",
    "# optimizer2 = torch.optim.SGD(model.parameters(), lr = 0.001, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "starttime = time.time()\n",
    "num_epochs = 50\n",
    "total_loss = []\n",
    "acc = []\n",
    "\n",
    "train(model, device, train_dataloader, optimizer1, 0, loss_fn)\n",
    "total_loss_0, acc_0 = evaluate(model, device, valid_dataloader,loss_fn, 0)\n",
    "torch.save(model.state_dict(),\"CIFAR10_cnn.pth\")    \n",
    "total_loss.append(total_loss_0)\n",
    "acc.append(acc_0)\n",
    "\n",
    "for epoch in range(1,num_epochs):\n",
    "    print(\"Training epoch:\", epoch)\n",
    "    # if epoch<20:\n",
    "    train(model, device, train_dataloader, optimizer1, epoch, loss_fn)\n",
    "    # else: \n",
    "        # train(model, device, train_dataloader, optimizer2, epoch, loss_fn)\n",
    "    \n",
    "    total_loss_0, acc_0 = evaluate(model, device, valid_dataloader,loss_fn, 0)\n",
    "    if total_loss_0 < min(total_loss) and acc_0 > max(acc):\n",
    "        torch.save(model.state_dict(),\"CIFAR10_cnn.pth\")\n",
    "    total_loss.append(total_loss_0)\n",
    "    acc.append(acc_0)\n",
    "\n",
    "model_ready = MyNet(num_features,hidden_size,output_size).to(device)\n",
    "model_ready.load_state_dict(torch.load('CIFAR10_cnn.pth'))\n",
    "evaluate(model_ready, device, test_dataloader,loss_fn, 1)\n",
    "\n",
    "endtime = time.time()\n",
    "time_cost = endtime - starttime\n",
    "print(\"Finish! running time: %.8s s\" % time_cost)\n",
    "\n",
    "x1 = range(0, num_epochs)\n",
    "x2 = range(0, num_epochs)\n",
    "y1 = acc\n",
    "y2 = total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set:0.8016\n",
      "Finish! run time: 812.4841 s\n"
     ]
    }
   ],
   "source": [
    "# test part\n",
    "model_ready = testNet(num_features,hidden_size,output_size).to(device)\n",
    "model_ready.load_state_dict(torch.load('CIFAR10_cnn.pth'))\n",
    "evaluate(model_ready, device, test_dataloader,loss_fn, 1)\n",
    "\n",
    "endtime = time.time()\n",
    "dtime = endtime - starttime\n",
    "print(\"Finish! run time: %.8s s\" % dtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10271104\n"
     ]
    }
   ],
   "source": [
    "model = VGG_A(num_features,hidden_size,output_size).to(device)\n",
    "print(cal_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制结果\n",
    "plt.clf()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(x1, y1, 'o-')\n",
    "plt.title('valid accuracy vs. epoches')\n",
    "plt.ylabel('valid accuracy')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(x2, y2, '.-')\n",
    "plt.xlabel('epoches')\n",
    "plt.ylabel('valid loss')\n",
    "\n",
    "plt.savefig(\"newNet_accuracy_loss.jpg\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f94c22818100bcf418777d014cb985992422586d7083e5bbade2e4897ac34b6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('zxy_virtualenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
